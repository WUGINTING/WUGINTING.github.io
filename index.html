<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>吳灌庭的家</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="吳灌庭的家">
<meta property="og:url" content="https://wuginting.github.io/index.html">
<meta property="og:site_name" content="吳灌庭的家">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="Ginting Wu">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="吳灌庭的家" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<!-- hexo injector head_end start --><link rel="stylesheet" href="/css/custom.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 8.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">吳灌庭的家</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">歡迎來到我的個人空間</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜尋"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜尋"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://wuginting.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-【AI分享】ProMem-Proactive-Memory-Extraction-的研究為-LLM-Agent-的記憶管理帶來了從「被動摘要」到「主動認知」的範式轉移" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2026/02/13/%E3%80%90AI%E5%88%86%E4%BA%AB%E3%80%91ProMem-Proactive-Memory-Extraction-%E7%9A%84%E7%A0%94%E7%A9%B6%E7%82%BA-LLM-Agent-%E7%9A%84%E8%A8%98%E6%86%B6%E7%AE%A1%E7%90%86%E5%B8%B6%E4%BE%86%E4%BA%86%E5%BE%9E%E3%80%8C%E8%A2%AB%E5%8B%95%E6%91%98%E8%A6%81%E3%80%8D%E5%88%B0%E3%80%8C%E4%B8%BB%E5%8B%95%E8%AA%8D%E7%9F%A5%E3%80%8D%E7%9A%84%E7%AF%84%E5%BC%8F%E8%BD%89%E7%A7%BB/" class="article-date">
  <time class="dt-published" datetime="2026-02-13T03:18:37.000Z" itemprop="datePublished">2026-02-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2026/02/13/%E3%80%90AI%E5%88%86%E4%BA%AB%E3%80%91ProMem-Proactive-Memory-Extraction-%E7%9A%84%E7%A0%94%E7%A9%B6%E7%82%BA-LLM-Agent-%E7%9A%84%E8%A8%98%E6%86%B6%E7%AE%A1%E7%90%86%E5%B8%B6%E4%BE%86%E4%BA%86%E5%BE%9E%E3%80%8C%E8%A2%AB%E5%8B%95%E6%91%98%E8%A6%81%E3%80%8D%E5%88%B0%E3%80%8C%E4%B8%BB%E5%8B%95%E8%AA%8D%E7%9F%A5%E3%80%8D%E7%9A%84%E7%AF%84%E5%BC%8F%E8%BD%89%E7%A7%BB/">【AI分享】LLM Agent 的記憶管理帶來了從「被動摘要」到「主動認知」的範式轉移</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="ProMem：從被動摘要到主動認知的範式轉移"><a href="#ProMem：從被動摘要到主動認知的範式轉移" class="headerlink" title="ProMem：從被動摘要到主動認知的範式轉移"></a>ProMem：從被動摘要到主動認知的範式轉移</h1><p><strong>發布日期：</strong> 2026-02-13</p>
<h2 id="研究概述"><a href="#研究概述" class="headerlink" title="研究概述"></a>研究概述</h2><p>ProMem (Proactive Memory Extraction) 為 LLM Agent 的記憶管理帶來了革命性的突破，實現了從「被動摘要」到「主動認知」的範式轉移。</p>
<p>簡單來說，它不再讓 AI 只是盲目地把對話變短，而是讓 AI 學會「反思」並「質疑」自己記下的東西是否正確且完整。</p>
<hr>
<h3 id="商業應用"><a href="#商業應用" class="headerlink" title="商業應用"></a>商業應用</h3><p>在AI導入時用戶普遍都希望有AI越用用聰明的傾向，但在實務上強化學習的方式是不成熟的，要做到這件事目前是不可能，但ProMem的這種「主動認知」的記憶管理方式，讓我們看到了在不改變模型架構的前提下，通過優化記憶提取流程來提升AI性能的可行性。</p>
<h2 id="核心技術貢獻與突破"><a href="#核心技術貢獻與突破" class="headerlink" title="核心技術貢獻與突破"></a>核心技術貢獻與突破</h2><h3 id="1-理論創新：引入「循環處理理論」-RPT"><a href="#1-理論創新：引入「循環處理理論」-RPT" class="headerlink" title="1. 理論創新：引入「循環處理理論」(RPT)"></a>1. 理論創新：引入「循環處理理論」(RPT)</h3><p>目前的記憶方法大多是「前饋式」（Feed-forward）的摘要，像是盲人摸象，提取時不知道未來任務是什麼，容易漏掉細節。</p>
<p><strong>ProMem 的創新：</strong></p>
<ul>
<li>借鑒了認知科學中的 RPT 理論</li>
<li>將記憶提取從一次性的動作轉變為具備**回饋循環（Feedback Loop）**的迭代過程</li>
</ul>
<h2 id="核心技術貢獻與突破-1"><a href="#核心技術貢獻與突破-1" class="headerlink" title="核心技術貢獻與突破"></a>核心技術貢獻與突破</h2><h3 id="1-理論創新：引入「循環處理理論」-RPT-1"><a href="#1-理論創新：引入「循環處理理論」-RPT-1" class="headerlink" title="1. 理論創新：引入「循環處理理論」(RPT)"></a>1. 理論創新：引入「循環處理理論」(RPT)</h3><p>目前的記憶方法大多是「前饋式」（Feed-forward）的摘要，像是盲人摸象，提取時不知道未來任務是什麼，容易漏掉細節。</p>
<p><strong>ProMem 的創新：</strong></p>
<ul>
<li>借鑒了認知科學中的 RPT 理論</li>
<li>將記憶提取從一次性的動作轉變為具備**回饋循環（Feedback Loop）**的迭代過程</li>
</ul>
<h3 id="2-三階段主動提取框架-ProMem-Framework"><a href="#2-三階段主動提取框架-ProMem-Framework" class="headerlink" title="2. 三階段主動提取框架 (ProMem Framework)"></a>2. 三階段主動提取框架 (ProMem Framework)</h3><p>ProMem 將記憶處理具體化為三個可執行的階段，解決了資訊丟失與幻覺問題：</p>
<h4 id="階段一：初始掃視-Initial-Extraction"><a href="#階段一：初始掃視-Initial-Extraction" class="headerlink" title="階段一：初始掃視 (Initial Extraction)"></a>階段一：初始掃視 (Initial Extraction)</h4><p><strong>怎麼做的：</strong></p>
<ul>
<li>LLM 一次性掃過所有對話歷史 D</li>
<li>使用提取提示詞 P_extract 指導 LLM 識別「可能重要的事實」</li>
<li>快速生成初版記憶條目集合 M_init</li>
<li><strong>問題：</strong> 這一步很快，但容易遺漏細節（就像走馬看花）</li>
</ul>
<h4 id="階段二：語義補全-Memory-Completion"><a href="#階段二：語義補全-Memory-Completion" class="headerlink" title="階段二：語義補全 (Memory Completion)"></a>階段二：語義補全 (Memory Completion)</h4><p><strong>怎麼做的：</strong></p>
<ol>
<li><p><strong>計算覆蓋缺口</strong></p>
<ul>
<li>將每個對話輪次轉成向量（embedding）</li>
<li>將 M_init 中的每條記憶也轉成向量</li>
<li>用向量相似度比對：哪些對話輪次「沒有對應的記憶」？</li>
</ul>
</li>
<li><p><strong>針對性二次提取</strong></p>
<ul>
<li>對那些「被遺漏的對話輪次」單獨再跑一次提取</li>
<li>生成補充記憶 M_supp</li>
<li>合併成更完整的記憶集 M &#x3D; M_init ∪ M_supp</li>
</ul>
</li>
</ol>
<p><strong>為什麼有效：</strong></p>
<ul>
<li>不是盲目地重跑，而是「有目標地補洞」</li>
<li>確保對話的每個部分都有對應的記憶條目</li>
</ul>
<h4 id="階段三：自我驗證-Memory-Verification-⭐-最關鍵的創新"><a href="#階段三：自我驗證-Memory-Verification-⭐-最關鍵的創新" class="headerlink" title="階段三：自我驗證 (Memory Verification) ⭐ 最關鍵的創新"></a>階段三：自我驗證 (Memory Verification) ⭐ 最關鍵的創新</h4><p><strong>怎麼做的：</strong></p>
<ol>
<li><p><strong>自我提問（Self-Questioning）</strong></p>
<ul>
<li>對每條記憶條目，LLM 自己產生一個驗證問題</li>
<li>例如記憶是「使用者喜歡藍色」→ 問題是「使用者最喜歡什麼顏色？」</li>
</ul>
</li>
<li><p><strong>回源查證（Grounding）</strong></p>
<ul>
<li>用這個問題去原始對話 D 中搜尋答案</li>
<li>如果找到支持證據 → 保留記憶</li>
<li>如果找不到證據或答案矛盾 → <strong>刪除這條「幻覺記憶」</strong></li>
</ul>
</li>
<li><p><strong>迭代精煉</strong></p>
<ul>
<li>這是一個回饋循環：質疑 → 查證 → 修正</li>
<li>類似人類回想時會「想不起來就翻筆記確認」</li>
</ul>
</li>
</ol>
<p><strong>為什麼是突破：</strong></p>
<ul>
<li>傳統方法只管「提取」，不管「對不對」</li>
<li>ProMem 加入了「自我懷疑」機制，主動剔除不可靠的記憶</li>
<li>每條進入長期記憶庫的資訊都經過「原文核實」</li>
</ul>
<h3 id="3-解決「摘要盲點」與「幻覺累積」"><a href="#3-解決「摘要盲點」與「幻覺累積」" class="headerlink" title="3. 解決「摘要盲點」與「幻覺累積」"></a>3. 解決「摘要盲點」與「幻覺累積」</h3><p><strong>主動探究：</strong></p>
<ul>
<li>解決了摘要方法因為不知道未來任務而遺漏重要細節的缺點</li>
</ul>
<p><strong>根植性（Grounding）：</strong></p>
<ul>
<li>確保每一條存入長期記憶庫的資訊都經過原始文本的核實</li>
<li>大幅降低了記憶幻覺</li>
</ul>
<hr>
<h2 id="實驗數據與實務價值"><a href="#實驗數據與實務價值" class="headerlink" title="實驗數據與實務價值"></a>實驗數據與實務價值</h2><p>根據論文提供的數據，ProMem 在多個維度上表現卓越：</p>
<table>
<thead>
<tr>
<th>評估指標</th>
<th>ProMem 表現</th>
<th>備註</th>
</tr>
</thead>
<tbody><tr>
<td><strong>記憶完整性 (Recall)</strong></td>
<td>73.80%</td>
<td>遠超基線方法的 41%-43%</td>
</tr>
<tr>
<td><strong>QA 準確性 (LongMemEval)</strong></td>
<td>69.57%</td>
<td>超越 SOTA 方法 LightMem</td>
</tr>
<tr>
<td><strong>抗壓縮能力</strong></td>
<td>極高</td>
<td>在輸入文本壓縮至 0.2 的情況下，性能依舊穩定</td>
</tr>
<tr>
<td><strong>小模型友善度</strong></td>
<td>+10.74%</td>
<td>在使用 Llama3-8B 等小模型時，進步幅度更顯著</td>
</tr>
</tbody></table>
<hr>
<h2 id="實務意義總結"><a href="#實務意義總結" class="headerlink" title="實務意義總結"></a>實務意義總結</h2><p>這項研究向我們證明了一個重要原則：</p>
<blockquote>
<p><strong>「高品質的數據（精煉過的記憶）比更強大的演算法更重要」</strong></p>
</blockquote>
<h3 id="成本與效益分析"><a href="#成本與效益分析" class="headerlink" title="成本與效益分析"></a>成本與效益分析</h3><p><strong>成本考量：</strong></p>
<ul>
<li>ProMem 會消耗較多的 Token（因為要不斷提問與回看）</li>
</ul>
<p><strong>長期價值：</strong></p>
<ul>
<li>記憶是「一次寫入、多次讀取」的資產</li>
<li>通常在後台異步運行</li>
<li>這種「精雕細琢」的開銷在長期交互中是非常划算的權衡</li>
</ul>
<h3 id="核心價值"><a href="#核心價值" class="headerlink" title="核心價值"></a>核心價值</h3><p>這篇論文就像是給了 AI Agent 一個**「筆記查證機制」**，讓它不再只是一個會忘詞的聊天機器人，而是一個能透過不斷自我質疑來確保資訊絕對可靠的專業助理。</p>
<h3 id="參考"><a href="#參考" class="headerlink" title="參考"></a>參考</h3><h2 id="https-arxiv-org-abs-2601-04463"><a href="#https-arxiv-org-abs-2601-04463" class="headerlink" title="https://arxiv.org/abs/2601.04463"></a><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2601.04463">https://arxiv.org/abs/2601.04463</a></h2><p><strong>標籤：</strong> AI, LLM, Memory Management, ProMem, Agent, Cognitive Science</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://wuginting.github.io/2026/02/13/%E3%80%90AI%E5%88%86%E4%BA%AB%E3%80%91ProMem-Proactive-Memory-Extraction-%E7%9A%84%E7%A0%94%E7%A9%B6%E7%82%BA-LLM-Agent-%E7%9A%84%E8%A8%98%E6%86%B6%E7%AE%A1%E7%90%86%E5%B8%B6%E4%BE%86%E4%BA%86%E5%BE%9E%E3%80%8C%E8%A2%AB%E5%8B%95%E6%91%98%E8%A6%81%E3%80%8D%E5%88%B0%E3%80%8C%E4%B8%BB%E5%8B%95%E8%AA%8D%E7%9F%A5%E3%80%8D%E7%9A%84%E7%AF%84%E5%BC%8F%E8%BD%89%E7%A7%BB/" data-id="cuidVEQYOZ1LDDd7RLkDBmHI8" data-title="【AI分享】LLM Agent 的記憶管理帶來了從「被動摘要」到「主動認知」的範式轉移" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-測試" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2026/02/13/%E6%B8%AC%E8%A9%A6/" class="article-date">
  <time class="dt-published" datetime="2026-02-13T02:57:31.000Z" itemprop="datePublished">2026-02-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2026/02/13/%E6%B8%AC%E8%A9%A6/">測試</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>歡迎來到我的部落格！</p>
<p>這是一篇測試文章。你可以在這裡寫下你的想法、分享你的經驗，或者記錄你的學習歷程。</p>
<h2 id="為什麼部落格只顯示一行字？"><a href="#為什麼部落格只顯示一行字？" class="headerlink" title="為什麼部落格只顯示一行字？"></a>為什麼部落格只顯示一行字？</h2><p>之前部落格只顯示標題，是因為文章內容區域是空的。現在我已經添加了一些內容，你應該可以看到完整的文章了。</p>
<h2 id="如何撰寫新文章？"><a href="#如何撰寫新文章？" class="headerlink" title="如何撰寫新文章？"></a>如何撰寫新文章？</h2><ol>
<li>在 <code>source/_posts/</code> 目錄下創建新的 Markdown 文件</li>
<li>在文件開頭添加 front matter（標題、日期等）</li>
<li>在 front matter 下方寫下你的文章內容</li>
<li>使用 <code>hexo generate</code> 重新生成靜態文件</li>
<li>使用 <code>hexo server</code> 預覽你的部落格</li>
</ol>
<p>祝你寫作愉快！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://wuginting.github.io/2026/02/13/%E6%B8%AC%E8%A9%A6/" data-id="cuidbfygYqTKwDLnwOa3uQnds" data-title="測試" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">彙整</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2026/02/">二月 2026</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2026/02/13/%E3%80%90AI%E5%88%86%E4%BA%AB%E3%80%91ProMem-Proactive-Memory-Extraction-%E7%9A%84%E7%A0%94%E7%A9%B6%E7%82%BA-LLM-Agent-%E7%9A%84%E8%A8%98%E6%86%B6%E7%AE%A1%E7%90%86%E5%B8%B6%E4%BE%86%E4%BA%86%E5%BE%9E%E3%80%8C%E8%A2%AB%E5%8B%95%E6%91%98%E8%A6%81%E3%80%8D%E5%88%B0%E3%80%8C%E4%B8%BB%E5%8B%95%E8%AA%8D%E7%9F%A5%E3%80%8D%E7%9A%84%E7%AF%84%E5%BC%8F%E8%BD%89%E7%A7%BB/">【AI分享】LLM Agent 的記憶管理帶來了從「被動摘要」到「主動認知」的範式轉移</a>
          </li>
        
          <li>
            <a href="/2026/02/13/%E6%B8%AC%E8%A9%A6/">測試</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2026 Ginting Wu<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>